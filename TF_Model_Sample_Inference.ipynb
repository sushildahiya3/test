{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIYG0fdVBssu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"/content/drive/MyDrive/Vipas_LLM_Example/Tensorflow_Model\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = TFT5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Input text\n",
        "input_text = \"Answer: The capital of france is?.\"\n",
        "\n",
        "# Tokenize input text\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"tf\")\n",
        "\n",
        "# Generate output\n",
        "outputs = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Text:\", generated_text)"
      ]
    }
  ]
}